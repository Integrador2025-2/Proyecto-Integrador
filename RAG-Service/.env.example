# Variables de entorno para Docker Compose
# Copia este archivo a .env y completa con tus valores

# Configuracion del servicio RAG

# Proveedor de LLM (openai o gemini)
LLM_PROVIDER=gemini
LLM_TEMPERATURE=0.3

# OpenAI (solo si LLM_PROVIDER=openai)
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini

# Google Gemini (solo si LLM_PROVIDER=gemini)
GEMINI_API_KEY=your_gemini_api_key_here
# Modelo mejorado (recomendado para respuestas largas)
GEMINI_MODEL=gemini-2.5-flash

# Tokens m√°ximos de salida (para respuestas muy largas)
GEMINI_MAX_OUTPUT_TOKENS=8192
GEMINI_MAX_OUTPUT_TOKENS_BUDGET=8192
GEMINI_MAX_OUTPUT_TOKENS_PLAN=8192

# Embeddings
EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2
CHROMA_DB_PATH=./chroma_db

# Configuracion del backend .NET
BACKEND_API_URL=http://host.docker.internal:5000
BACKEND_API_KEY=your_backend_api_key_here

# Configuracion de archivos
UPLOAD_DIR=./uploads
GENERATED_BUDGETS_DIR=./generated_budgets
MAX_FILE_SIZE_MB=50

# Configuracion de la aplicacion
DEBUG=False
LOG_LEVEL=INFO
